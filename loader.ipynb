{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Loader\n",
    "\n",
    "This notebook is used to load jobs in this repo to the `wandb/jobs` public project.\n",
    "- You will need to be logged into wandb and have access to the `wandb` entity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kill ports ahead of spinning up containers (you may need to restart docker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lsof -i TCP:3307 | grep LISTEN | awk '{print $2}' | xargs kill -9\n",
    "!lsof -i TCP:8000 | grep LISTEN | awk '{print $2}' | xargs kill -9\n",
    "!open /Applications/Docker.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%env WANDB_API_KEY {wandb.api.api_key}\n",
    "%env WANDB_ENTITY wandb\n",
    "%env WANDB_PROJECT jobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_RUN_GROUP=python\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_RUN_GROUP python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The SQL Query job depends on access to a database.  You can load this dummy database with the snippet below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc792be730733e8b72a7e4aba7e84a6c85148460ae8c6088bd6a23514b32029c\n",
      "env: MYSQL_USER=sakila\n",
      "env: MYSQL_PASSWORD=p_ssW0rd\n"
     ]
    }
   ],
   "source": [
    "!docker run -p 3307:3306 -d sakiladb/mysql:latest\n",
    "%env MYSQL_USER sakila\n",
    "%env MYSQL_PASSWORD p_ssW0rd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run python jobs as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('jobs/hello_world/job.py'),\n",
       " PosixPath('jobs/sql_query_artifact/job.py'),\n",
       " PosixPath('jobs/sql_query_table/job.py'),\n",
       " PosixPath('jobs/msft_teams_webhook/job.py'),\n",
       " PosixPath('jobs/http_webhook/job.py'),\n",
       " PosixPath('jobs/github_actions_workflow_dispatch/job.py')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_jobs = list(Path('jobs').glob('**/*job.py'))\n",
    "python_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in python_jobs:\n",
    "    %env WANDB_NAME {job.parent.name}\n",
    "    %env WANDB_JOBS_REPO_CONFIG {job.parent/'config.yml'}\n",
    "    !python {job}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker jobs\n",
    "- These jobs touch AWS, so they mount the `.aws` directory.\n",
    "- If you need to see the literal command, prepend `set -x &&` to the shell command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env WANDB_RUN_GROUP docker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Endpoints job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_NAME=deploy_to_sagemaker_endpoints\n",
      "env: WANDB_JOBS_REPO_CONFIG=config_tensorflow.yml\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                                         \n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 343B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.9-buster       0.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 343B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.9-buster       0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 343B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.9-buster       0.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (3/4)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 343B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.9-buster       0.5s\n",
      "\u001b[34m => [auth] library/python:pull token for registry-1.docker.io              0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.7s (12/12) FINISHED                                              \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 343B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.9-buster       0.6s\n",
      "\u001b[0m\u001b[34m => [auth] library/python:pull token for registry-1.docker.io              0.0s\n",
      "\u001b[0m\u001b[34m => [1/6] FROM docker.io/library/python:3.9-buster@sha256:dda953d28cdcf52  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.09kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/6] WORKDIR /launch                                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/6] COPY requirements.txt ./                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/6] RUN pip install -r requirements.txt                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/6] COPY deploy_to_sagemaker_endpoints.py inference.py ./     0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [6/6] COPY config_pytorch.yml config_tensorflow.yml ./          0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:4ad997d26ae196339a9bcc28efb3fb55f85b311c00bbe  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/deploy_to_sagemaker_endpoints           0.0s\n",
      "\u001b[0m\u001b[?25h\n",
      "Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n",
      "wandb: Currently logged in as: megatruong (wandb). Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.14.0\n",
      "wandb: Run data is saved locally in /launch/wandb/run-20230320_030350-8y6iekn1\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run deploy_to_sagemaker_endpoints\n",
      "wandb: ⭐️ View project at https://wandb.ai/wandb/jobs\n",
      "wandb: 🚀 View run at https://wandb.ai/wandb/jobs/runs/8y6iekn1\n",
      "wandb: sagemaker job: Downloading artifact from wandb\n",
      "wandb: Downloading large artifact model-sage-feather-1:v2, 273.69MB. 4 files... \n",
      "wandb:   4 of 4 files downloaded.  \n",
      "Done. 0:0:4.9\n",
      "wandb: sagemaker job: Creating temp directory for sagemaker model\n",
      "wandb: sagemaker job: Uploading model to S3\n",
      "wandb: sagemaker job: Deploy model to Sagemaker Endpoints (this may take a while...)\n",
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "---The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "wandb: sagemaker job: Successfully deployed endpoint: tensorflow-inference-2023-03-20-03-04-16-999\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "!wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\n",
      "wandb: Run summary:\n",
      "wandb: sagemaker_endpoint tensorflow-inference...\n",
      "wandb: \n",
      "wandb: 🚀 View run deploy_to_sagemaker_endpoints at: https://wandb.ai/wandb/jobs/runs/8y6iekn1\n",
      "wandb: Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230320_030350-8y6iekn1/logs\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_NAME deploy_to_sagemaker_endpoints\n",
    "%env WANDB_JOBS_REPO_CONFIG config_tensorflow.yml\n",
    "\n",
    "!docker build -t $WANDB_NAME jobs/deploy_to_sagemaker_endpoints && \\\n",
    "docker run \\\n",
    "   -v $HOME/.aws:/root/.aws:ro \\\n",
    "   -e WANDB_API_KEY=$WANDB_API_KEY \\\n",
    "   -e WANDB_ENTITY=$WANDB_ENTITY \\\n",
    "   -e WANDB_PROJECT=$WANDB_PROJECT \\\n",
    "   -e WANDB_NAME=$WANDB_NAME \\\n",
    "   -e WANDB_RUN_GROUP=$WANDB_RUN_GROUP \\\n",
    "   -e WANDB_JOBS_REPO_CONFIG=$WANDB_JOBS_REPO_CONFIG \\\n",
    "   $WANDB_NAME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nvidia Triton Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This job requires a running Triton Server.  You can start one with this snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_PRELOAD=\"/usr/lib/aarch64-linux-gnu/libgomp.so.1\"\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                                         \n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 208B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for nvcr.io/nvidia/tritonserver:22.11-py3     0.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 208B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for nvcr.io/nvidia/tritonserver:22.11-py3     0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 208B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for nvcr.io/nvidia/tritonserver:22.11-py3     0.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 208B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for nvcr.io/nvidia/tritonserver:22.11-py3     0.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.8s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 208B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for nvcr.io/nvidia/tritonserver:22.11-py3     0.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 208B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for nvcr.io/nvidia/tritonserver:22.11-py3     0.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.1s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 208B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for nvcr.io/nvidia/tritonserver:22.11-py3     1.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.2s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 208B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for nvcr.io/nvidia/tritonserver:22.11-py3     1.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.3s (3/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 208B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for nvcr.io/nvidia/tritonserver:22.11-py3     1.3s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.4s (5/5) FINISHED                                                \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 208B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for nvcr.io/nvidia/tritonserver:22.11-py3     1.3s\n",
      "\u001b[0m\u001b[34m => CACHED [1/1] FROM nvcr.io/nvidia/tritonserver:22.11-py3@sha256:1cb912  0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:ab9311471be5b45a081bd48854152e541d8be1267bd58  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/tritonserver-wandb                      0.0s\n",
      "\u001b[0m\u001b[?25h\n",
      "Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n",
      "WARNING: Published ports are discarded when using host network mode\n",
      "7e3303c8026804b10bc066bc7b3dc9aacfd68b814a33378dc3589c3059de6934\n"
     ]
    }
   ],
   "source": [
    "# you may need this export on M1\n",
    "# related: https://github.com/keras-team/keras-tuner/issues/317#issuecomment-640181692\n",
    "%env LD_PRELOAD=\"/usr/lib/aarch64-linux-gnu/libgomp.so.1\"\n",
    "\n",
    "!docker build -t tritonserver-wandb jobs/deploy_to_nvidia_triton/server && \\\n",
    "docker run \\\n",
    "  -v $HOME/.aws:/root/.aws:ro \\\n",
    "  -p 8000:8000 \\\n",
    "  --rm --net=host -d \\\n",
    "  tritonserver-wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then launch the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_NAME=deploy_to_nvidia_triton\n",
      "env: WANDB_JOBS_REPO_CONFIG=config_tensorflow.yml\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                                         \n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 74B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.9-buster       0.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 74B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/library/python:3.9-buster       0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.4s (5/10)                                                        \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 74B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.9-buster       0.3s\n",
      "\u001b[0m\u001b[34m => [1/6] FROM docker.io/library/python:3.9-buster@sha256:dda953d28cdcf52  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 274B                                          0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.4s (11/11) FINISHED                                              \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 74B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.9-buster       0.3s\n",
      "\u001b[0m\u001b[34m => [1/6] FROM docker.io/library/python:3.9-buster@sha256:dda953d28cdcf52  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 274B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/6] WORKDIR /launch                                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/6] COPY requirements.txt ./                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/6] RUN pip install -r requirements.txt                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/6] COPY deploy_to_nvidia_triton.py ./                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [6/6] COPY config_pytorch.yml config_tensorflow.yml ./          0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:2902fb323b0d8ad1dd5feb95f1be207e03c4098d69eb8  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/deploy_to_nvidia_triton                 0.0s\n",
      "\u001b[0m\u001b[?25h\n",
      "Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n",
      "wandb: Currently logged in as: megatruong (wandb). Use `wandb login --relogin` to force relogin\n",
      "wandb: ERROR wandb version 0.13.8.dev1 has been retired!  Please upgrade.\n",
      "wandb: wandb version 0.14.0 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "wandb: Tracking run with wandb version 0.13.8.dev1\n",
      "wandb: Run data is saved locally in /launch/wandb/run-20230320_030636-6dflhymz\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run deploy_to_nvidia_triton\n",
      "wandb: ⭐️ View project at https://wandb.ai/wandb/jobs\n",
      "wandb: 🚀 View run at https://wandb.ai/wandb/jobs/runs/6dflhymz\n",
      "wandb: triton job: Downloading wandb artifact\n",
      "wandb: Downloading large artifact model-sage-feather-1:v3, 273.69MB. 4 files... \n",
      "wandb:   4 of 4 files downloaded.  \n",
      "Done. 0:0:5.4\n",
      "wandb: triton job: Uploading model to Triton model repo (this may take a while...)\n",
      "wandb: Uploading saved_model.pb to models/model-sage-feather-1/3/model.savedmodel/saved_model.pb\n",
      "wandb: Uploading keras_metadata.pb to models/model-sage-feather-1/3/model.savedmodel/keras_metadata.pb\n",
      "wandb: Uploading variables/variables.data-00000-of-00001 to models/model-sage-feather-1/3/model.savedmodel/variables/variables.data-00000-of-00001\n",
      "wandb: Uploading variables/variables.index to models/model-sage-feather-1/3/model.savedmodel/variables/variables.index\n",
      "wandb: triton job: Loading model into Triton\n",
      "wandb: WARNING Did not find config.pbtxt for model-sage-feather-1/3.  Trying to autogenerate config...\n",
      "wandb: Using autogenerated config for model-sage-feather-1/3\n",
      "wandb: Generated config at: overloaded_config.pbtxt\n",
      "wandb: triton job: Finished deploying to Triton\n",
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: Synced deploy_to_nvidia_triton: https://wandb.ai/wandb/jobs/runs/6dflhymz\n",
      "wandb: Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230320_030636-6dflhymz/logs\n",
      "wandb: ERROR wandb version 0.13.8.dev1 has been retired!  Please upgrade.\n",
      "wandb: wandb version 0.14.0 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_NAME deploy_to_nvidia_triton\n",
    "%env WANDB_JOBS_REPO_CONFIG config_tensorflow.yml\n",
    "\n",
    "!docker build -t $WANDB_NAME jobs/deploy_to_nvidia_triton/deployer && \\\n",
    "docker run \\\n",
    "   -v $HOME/.aws:/root/.aws:ro \\\n",
    "   -e WANDB_API_KEY=$WANDB_API_KEY \\\n",
    "   -e WANDB_ENTITY=$WANDB_ENTITY \\\n",
    "   -e WANDB_PROJECT=$WANDB_PROJECT \\\n",
    "   -e WANDB_NAME=$WANDB_NAME \\\n",
    "   -e WANDB_RUN_GROUP=$WANDB_RUN_GROUP \\\n",
    "   -e WANDB_JOBS_REPO_CONFIG=$WANDB_JOBS_REPO_CONFIG \\\n",
    "   --rm --net=host \\\n",
    "   $WANDB_NAME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nvidia Tensor RT Conversion Job\n",
    "This job requires a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_NAME=optimize_with_nvidia_tensorrt\n",
      "unable to prepare context: path \"jobs/optimize-with-tensor-rt\" not found\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_NAME optimize_with_nvidia_tensorrt\n",
    "\n",
    "!docker build -t $WANDB_NAME jobs/optimize-with-tensor-rt && \\\n",
    "docker run \\\n",
    "    --gpus all \\\n",
    "    --runtime=nvidia \\\n",
    "    -e WANDB_API_KEY=$WANDB_API_KEY \\\n",
    "    -e WANDB_ENTITY=$WANDB_ENTITY \\\n",
    "    -e WANDB_PROJECT=$WANDB_PROJECT \\\n",
    "    -e WANDB_RUN_GROUP=$WANDB_RUN_GROUP \\\n",
    "    -e WANDB_NAME=$WANDB_NAME \\\n",
    "    $WANDB_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylaunch39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
